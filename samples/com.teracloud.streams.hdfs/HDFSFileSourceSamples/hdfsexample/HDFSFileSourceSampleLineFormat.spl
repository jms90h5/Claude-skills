/*******************************************************************************
* Copyright (C) 2014, International Business Machines Corporation
* All Rights Reserved
*******************************************************************************/                        

namespace hdfsexample ;

use com.teracloud.streams.hdfs::HDFS2FileSource ;
/**
 * The [HDFS2FileSourceSampleLineFormat] demonstrates how you can use the HDFS2FileSink operator
 * to read a file from the Hadoop file system.
 *
 * To build this application, you need to set up the HADOOP_HOME environment variable as follows:
 * * export HADOOP_HOME=<Hadoop installation>
 * 
 * Setup:
 * To run this sample, you will need to copy the input file from the sample's data directory to 
 * the Hadoop File System:
 * 1. At the command line, go to the sample's data directory.
 * 1. Run the following command to copy the file from the data directory to HDFS:
 *   * <HADOOP_HOME>/bin/hadoop fs -copyFromLocal LineFile.txt /user/<userId>
 *
 * If compiling and running from command line, follow these steps:
 *  1. Create a directory. For example, you can create a directory in your home directory.
 *   * mkdir $HOME/hdfssamples
 *  1. Copy the samples to this directory.
 *   * cp -R $STREAMS_INSTALL/toolkits/com.ibm.streams.bigdata/samples/* $HOME/hdfssamples/
 *  1. Build one of the sample applications. Go to the appropriate subdirectory and run the make. By default, the sample is compiled as a distributed application. If you want to compile the application as a standalone application, run make standalone instead. Run make clean to return the samples back to their original state.
 *  1. Run the sample application. 
 *   * To run the HDFS2FileSourceSampleLineFormat sample application in distributed mode, start your Streams instance, then use the streamtool command to submit the .adl files that were generated during the application build. 
 *    * streamtool submitjob -i <instance_name> output/Distributed/hdfsexample::HDFS2FileSourceSampleLineFormat/hdfsexample.HDFS2FileSourceSampleLineFormat.adl -P hdfsUri="hdfs://<machine_name>:<port>" -P hdfsUser="<user_name>" 
 *   * To run the HDFS2FileSourceSampleLineFormat sample application in standalone mode, issue the command:
 *    * ./output/Standalone/hdfsexample::HDFS2FileSourceSampleLineFormat/bin/standalone hdfsUri="hdfs://<machine_name>:<port>" hdfsUser="<user_name>" 
 *
 * @param hdfsUri URI to HDFS.  If unspecified, the operator expects that the HDFS URI is specified as the fs.defaultFS or fs.default.name property in core-site.xml.
 * @param hdfsUser User to connect to HDFS.  If unspecified the instance owner running the application will be used as the user
 * to log onto the HDFS. Example value: "streamsadmin"
 */
composite HDFS2FileSourceSampleLineFormat
{
	graph
		stream<rstring lines> LineStream = HDFS2FileSource()
		{
			param
				file : "LineInput.txt" ;
		} 

		() as MySink = FileSink(LineStream)
		{
			logic
				onTuple LineStream : 
					printStringLn(lines);
					
			param
				file : "LineSink.txt" ;
				flush : 1u ;
		}

}
